{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f716f37-bb32-46d4-9a4e-739f3e0be258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_files\n",
    "from utils import strip_webvtt_to_plain_text\n",
    "\n",
    "# Define the emotions of interest\n",
    "emotions = [\"ilo\", \"viha\", \"suru\", \"hämmästys\", \"pelko\", \"inho\"]\n",
    "\n",
    "# And read the texts of interest from the file system\n",
    "contents = read_files(folder=\"data/linnut-03\", prefix=\"inputfile\")\n",
    "# contents = read_files(folder=\"data/linnut\", prefix=\"nayte\")\n",
    "\n",
    "# Remove timestamps if present\n",
    "contents = [(fname, strip_webvtt_to_plain_text(text)) for fname, text in contents]\n",
    "\n",
    "# Print to check that texts are correctly read\n",
    "for fname, text in contents:\n",
    "    print(f\"{fname}:\\n\\n\")\n",
    "    print(f\"{text}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429be7b-1e37-4a57-9a1a-a62633a802d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "from llm import generate_simple\n",
    "\n",
    "# Here, we will go through every text and every code for some number of iterations, and ask the llm to decide whether the emotion applies to the text or not.\n",
    "# Asking the same question multiple gives us a reliability estimate.\n",
    "\n",
    "# Define a machine-readable output format that the llm should produce, i.e. a boolean value \"emotion_present\".\n",
    "output_format = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"emotion_present\": {\n",
    "            \"type\": \"boolean\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\n",
    "      \"emotion_present\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# For every text and code, generate {n_iter} decisions.\n",
    "n_iter = 2\n",
    "\n",
    "results = []\n",
    "for fname, text in contents:\n",
    "    for emotion in emotions:\n",
    "        for idx in range(n_iter):\n",
    "            \n",
    "            # Define the instructions. \n",
    "            instruction = \"\"\"\n",
    "            Olet laadullisen tutkimuksen avustaja. Saat tekstinäytteen sekä yhden ihmisen perustunteista. Lue teksti huolella ja päätä esiintyykö tunne tekstinäytteessä.\n",
    "            \"\"\"\n",
    "\n",
    "            # Define the content snippet given to the llm.\n",
    "            content = f\"Tunne: {emotion} \\n\\n Tekstinäyte: \\n\\n {text}\"\n",
    "\n",
    "            # Generate the answer\n",
    "            result = generate_simple(instruction, content, seed=idx, output_format=output_format)\n",
    "\n",
    "            # Extract the result\n",
    "            present = json.loads(result['message']['content'])['emotion_present']\n",
    "\n",
    "            # Store it\n",
    "            results.append({\n",
    "                \"fname\": fname,\n",
    "                \"emotion\": emotion,\n",
    "                \"iter\": idx,\n",
    "                \"result\": present\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3dccd8-bd43-4aae-bc10-93b438796785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Here we use pandas to construct a simple colored table out of the results.\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "transformed_data = {}\n",
    "\n",
    "# From the flat results structure, create hierarchical easier structure\n",
    "for item in results:\n",
    "    fname = item['fname']\n",
    "    emotion = item['emotion']\n",
    "    \n",
    "    if fname not in transformed_data:\n",
    "        transformed_data[fname] = {}\n",
    "    \n",
    "    if emotion not in transformed_data[fname]:\n",
    "        transformed_data[fname][emotion] = []\n",
    "    \n",
    "    transformed_data[fname][emotion].append(item['result'])\n",
    "\n",
    "# Calculate percentages of (\"yes\" / all) for each text and code.\n",
    "for fname in transformed_data:\n",
    "    for emotion in transformed_data[fname]:\n",
    "        true_count = transformed_data[fname][emotion].count(True)\n",
    "        total_count = len(transformed_data[fname][emotion])\n",
    "        transformed_data[fname][emotion] = (true_count / total_count) * 100\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame.from_dict(transformed_data, orient='index')\n",
    "\n",
    "# Add averages\n",
    "df['total'] = df.mean(axis=1)\n",
    "df.loc['total'] = df.mean()\n",
    "\n",
    "# Format percentages\n",
    "df = df.round(2)\n",
    "\n",
    "# Define the styling function\n",
    "def color_high_values(val):\n",
    "    color = 'background-color: rgba(144, 238, 144, 0.3)' if val >= 80 else ''\n",
    "    return color\n",
    "\n",
    "# Apply the styling\n",
    "styled_df = df.style.map(color_high_values).format(\"{:.2f}\")\n",
    "\n",
    "# Display the styled DataFrame\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d343fa33-be02-4ea6-9975-2fceefeed0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
